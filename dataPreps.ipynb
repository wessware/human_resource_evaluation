{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation techniques, Statistical Imputation transform for the horse colic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import isnan\n",
    "from pandas import read_csv\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the csv file\n",
    "dataframe = read_csv(\"G:\\\\data\\\\datasets\\\\horse.csv\", header=None, na_values='?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Missing: 1605\n"
    }
   ],
   "source": [
    "#split into input and output elements\n",
    "data = dataframe.values\n",
    "ix = [i for i in range(data.shape[1]) if i != 23]\n",
    "X, y = data[:, ix], data[:, 23]\n",
    "#print the total missing values\n",
    "print(\"Missing: %d\" % sum(isnan(X).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the imputer\n",
    "imputer = SimpleImputer(strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SimpleImputer()"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "#fit the imputer on the dataset\n",
    "imputer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the dataset\n",
    "Xtrans = imputer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Missing: 0\n"
    }
   ],
   "source": [
    "#print the total missing values\n",
    "print(\"Missing: %d\" % sum(isnan(Xtrans).flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0       1\n1       0\n2       0\n3      60\n4      24\n5      58\n6      56\n7      69\n8      47\n9      32\n10     55\n11     44\n12     56\n13    104\n14    106\n15    247\n16    102\n17    118\n18     29\n19     33\n20    165\n21    198\n22      1\n23      0\n24      0\n25      0\n26      0\n27      0\ndtype: int64"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"G:\\\\data\\\\datasets\\\\horse_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection Using the Recursive Feature Elimination Technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define RFE\n",
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RFE(estimator=DecisionTreeClassifier(), n_features_to_select=5)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#fit RFE\n",
    "rfe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Column: 0, Selected= False, Rank: 4\nColumn: 1, Selected= False, Rank: 5\nColumn: 2, Selected= True, Rank: 1\nColumn: 3, Selected= True, Rank: 1\nColumn: 4, Selected= True, Rank: 1\nColumn: 5, Selected= False, Rank: 6\nColumn: 6, Selected= True, Rank: 1\nColumn: 7, Selected= False, Rank: 2\nColumn: 8, Selected= True, Rank: 1\nColumn: 9, Selected= False, Rank: 3\n"
    }
   ],
   "source": [
    "#summarize all the features\n",
    "for i in range(X.shape[1]):\n",
    "    print(\"Column: %d, Selected= %s, Rank: %d\" % (i, rfe.support_[i], rfe.ranking_[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "data = pd.read_csv(\"G:\\\\data\\\\datasets\\\\breast_cancer.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, :-1].astype(str)\n",
    "Y = dataset[:, -1].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['50-59' 'ge40' '15-19' '0-2' 'no' '1' 'right' 'central' 'no']\n ['50-59' 'ge40' '35-39' '0-2' 'no' '2' 'left' 'left_low' 'no']\n ['40-49' 'premeno' '35-39' '0-2' 'yes' '3' 'right' 'left_low' 'yes']]\n"
    }
   ],
   "source": [
    "print(X[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_oe = encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0.]\n [0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0.]\n [0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n  0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1.]]\n"
    }
   ],
   "source": [
    "print(X_oe[:3, :])"
   ]
  },
  {
   "source": [
    "Scaling data with normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 2.39324489 -5.77732048 -0.59062319 -2.08095322  1.04707034]\n [-0.45820294  1.94683482 -2.46471441  2.36590955 -0.73666725]\n [ 2.35162422 -1.00061698 -0.5946091   1.12531096 -0.65267587]]\n"
    }
   ],
   "source": [
    "#define the dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=5, n_informative=5, n_redundant=0, random_state=1)\n",
    "#summarize the data before transformation\n",
    "print(X[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the scaler\n",
    "trans = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.77608466 0.0239289  0.48251588 0.18352101 0.59830036]\n [0.40400165 0.79590304 0.27369632 0.6331332  0.42104156]\n [0.77065362 0.50132629 0.48207176 0.5076991  0.4293882 ]]\n"
    }
   ],
   "source": [
    "X_norm = trans.fit_transform(X)\n",
    "print(X_norm[:3, :])"
   ]
  },
  {
   "source": [
    "Transforming numbers to categories using kBins"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "#define a dataset\n",
    "X, Y = make_classification(n_samples=1000, n_features=5, n_informative=5, n_redundant=0, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[ 2.39324489 -5.77732048 -0.59062319 -2.08095322  1.04707034]\n [-0.45820294  1.94683482 -2.46471441  2.36590955 -0.73666725]\n [ 2.35162422 -1.00061698 -0.5946091   1.12531096 -0.65267587]]\n"
    }
   ],
   "source": [
    "#summmarize the data before transformation\n",
    "print(X[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[7. 0. 4. 1. 5.]\n [4. 7. 2. 6. 4.]\n [7. 5. 4. 5. 4.]]\n"
    }
   ],
   "source": [
    "#define the transform\n",
    "trans = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
    "#transform the data\n",
    "X_discrete = trans.fit_transform(X)\n",
    "#summarize after data transform\n",
    "print(X_discrete[:3, :])"
   ]
  },
  {
   "source": [
    "Dimensionality Reduction with Principal Component Analysis\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-0.53448246  0.93837451  0.38969914  0.0926655   1.70876508  1.14351305\n  -1.47034214  0.11857673 -2.72241741  0.2953565 ]\n [-2.42280473 -1.02658758 -2.34792156 -0.82422408  0.59933419 -2.44832253\n   0.39750207  2.0265065   1.83374105  0.72430365]\n [-1.83391794 -1.1946668  -0.73806871  1.50947233  1.78047734  0.58779205\n  -2.78506977 -0.04163788 -1.25227833  0.99373587]]\n"
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA\n",
    "#define the dataset\n",
    "X, Y = make_classification(n_samples=1000, n_features=10, n_informative=3, n_redundant=7, random_state=1)\n",
    "#summarize the data beofore transform\n",
    "print(X[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define the transform\n",
    "trans = PCA(n_components=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[-0.53448246  0.93837451  0.38969914  0.0926655   1.70876508  1.14351305\n  -1.47034214  0.11857673 -2.72241741  0.2953565 ]\n [-2.42280473 -1.02658758 -2.34792156 -0.82422408  0.59933419 -2.44832253\n   0.39750207  2.0265065   1.83374105  0.72430365]\n [-1.83391794 -1.1946668  -0.73806871  1.50947233  1.78047734  0.58779205\n  -2.78506977 -0.04163788 -1.25227833  0.99373587]]\n"
    }
   ],
   "source": [
    "#transform the data\n",
    "X_dim = trans.fit_transform(X)\n",
    "print(X[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bit42fb4ec475c14e2b956cc15bf5c0fc9f",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}